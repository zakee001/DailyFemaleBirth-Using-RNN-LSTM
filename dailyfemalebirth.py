# -*- coding: utf-8 -*-
"""DailyFemaleBirth.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KBTuq4D27G02OktoaiU25SaoXF88zzix
"""

#importing libraries 
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import seaborn as sns

#reading the dataset
df = pd.read_csv('Women_Data.csv',index_col='Date', parse_dates = True)

#showing the first values of the dataset
df.head()

#plotting the values
df.plot(figsize=(15,10))

#checking the length of the data frame
len(df)

#rnn can work on non stationary data as well.
#dividing the data into test and train 
train = df.iloc[:334]
test = df.iloc[334:]

#importing min-max scaler for data normalization
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

#showing the head and tail of the data set
df.head(), df.tail()

#transforming the data between 0 and 1 
scaler.fit(train)
scaled_train = scaler.transform(train)
scaled_test = scaler.transform(test)

#testing if the values are between 0 and 1 
scaled_test[:10]

#selecting the number of inputs and setting the generator 
from keras.preprocessing.sequence import TimeseriesGenerator
input_data = 12
feautures= 1

generator = TimeseriesGenerator(scaled_train,scaled_train,length =input_data , batch_size =1)

#importing libraries for our model 
from keras.models import Sequential 
from keras.layers import Dense 
from keras.layers import LSTM

#defining our model 
model = Sequential()
model.add(LSTM(200,activation ='relu', input_shape= (input_data, feautures)))
model.add(Dense(1)) #final output layer 
model.compile(optimizer='adam', loss= 'mse')

#fitting the model
model.fit(generator, epochs = 50 )

#plotting the loss
loss_per_epoch = model.history.history['loss']
plt.plot(range(len(loss_per_epoch)),loss_per_epoch)

#taking the last trained batch to predict the first element 
last_trained_batch = scaled_train[-12:]

last_trained_batch = last_trained_batch.reshape(1,input_data,feautures)

model.predict(last_trained_batch)

#compairing with the first value of test data
scaled_test[0]

#predictions 
test_predictions =[]
first_eval_batch = scaled_train[-input_data:]
current_batch = first_eval_batch.reshape(1,input_data,feautures)

for i in range(len(test)):
    current_pred = model.predict(current_batch)[0]
    test_predictions.append(current_pred)
    current_batch = np.append(current_batch[:,1:,:],[[current_pred]], axis= 1)

test_predictions

true_predictions = scaler.inverse_transform(test_predictions)

test['Predictions'] = true_predictions

#compairing the actual values with the predicted ones
test.plot(figsize=(14,5))

#calculating the root mean squared error
from sklearn.metrics import mean_squared_error
from math import sqrt
rmse = sqrt(mean_squared_error(test['Births'],test['Predictions']))
print(rmse)

#compairing the actual values with the predicted ones 
test

